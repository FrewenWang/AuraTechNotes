---
title: AILearning的数学基础
date: 2020-07-20 00:00:00
updated: 2022-01-05 00:00:00
tags: [AI,机器学习,人工智能]
type: [AI,机器学习,人工智能]
comments: Activity的生命周期完全解析
description: Activity的生命周期完全解析
keywords: Activity的生命周期完全解析
top_img:
mathjax:
katex:
aside:
aplayer:
highlight_shrink:
---

[TOC]

# 概述

文章参考：https://zhuanlan.zhihu.com/p/25197792

我们知道，机器学习的特点就是：以计算机为工具和平台，以数据为研究对象，以学习方法为中心；是概率论、线性代数、数值计算、信息论、最优化理论和计算机科学等多个领域的交叉学科。所以本文就先介绍一下机器学习涉及到的一些最常用的的数学知识。



# 线性代数

## **标量**

一个标量就是一个单独的数，一般用小写的的变量名称表示。



## **向量**

一个向量就是一列数，这些数是有序排列的。用过次序中的索引，我们可以确定每个单独的数。通常会赋予向量粗体的小写名称。当我们需要明确表示向量中的元素时，我们会将元素排
列成一个方括号包围的纵柱：

![img](https://pic2.zhimg.com/80/v2-824f0739982920b1502ca01588d35e21_1440w.jpg)

我们可以把向量看作空间中的点，每个元素是不同的坐标轴上的坐标。



## **矩阵**

矩阵是二维数组，其中的每一个元素被两个索引而非一个所确定。我们通常会赋予矩阵粗体的大写变量名称，比如A。 如果一个实数矩阵高度为m，宽度为n，那么我们说**![[公式]](https://www.zhihu.com/equation?tex=A%5Cepsilon+R%5E%7Bm%5Ctimes+n%7D+)。**

![img](https://pic3.zhimg.com/80/v2-dd3017aa861f53973da40d860ec93732_1440w.jpg)

矩阵这东西在机器学习中就不要太重要了！实际上，如果我们现在有N个用户的数据，每条数据含有M个特征，那其实它对应的就是一个N*M的矩阵呀；再比如，一张图由16*16的像素点组成，那这就是一个16*16的矩阵了。现在才发现，我们大一学的矩阵原理原来这么的有用！要是当时老师讲课的时候先普及一下，也不至于很多同学学矩阵的时候觉得莫名其妙了。

## **张量**

几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。



例如，可以将任意一张彩色图片表示成一个三阶张量，三个维度分别是图片的高度、宽度和色彩数据。将这张图用张量表示出来，就是最下方的那张表格：

![img](https://pic1.zhimg.com/80/v2-c0c16793d4662bfcdd7e112030096f94_1440w.jpg)

​		其中表的横轴表示图片的宽度值，这里只截取0~319；表的纵轴表示图片的高度值，这里只截取0~4；表格中每个方格代表一个像素点，比如第一行第一列的表格数据为[1.0,1.0,1.0]，代表的就是RGB三原色在图片的这个位置的取值情况（即R=1.0，G=1.0，B=1.0）。

​		当然我们还可以将这一定义继续扩展，即：我们可以用四阶张量表示一个包含多张图片的数据集，这四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。

​		张量在深度学习中是一个很重要的概念，因为它是一个深度学习框架中的一个核心组件，后续的所有运算和优化算法几乎都是基于张量进行的。

