---
title: 机器学习线性回归基础
date: 2020-07-20 00:00:00
updated: 2022-01-05 00:00:00
tags: [Linux,四大组件,Activity]
type: [Linux,四大组件,Activity]
comments: Activity的生命周期完全解析
description: Activity的生命周期完全解析
keywords: Activity的生命周期完全解析
top_img:
mathjax:
katex:
aside:
aplayer:
highlight_shrink:
---



[TOC]

# 概述

文章参考：https://blog.csdn.net/weixin_42737442/article/details/99674262

文章参考：https://blog.csdn.net/fengxinlinux/article/details/86556584

文章参考：https://blog.csdn.net/xiazdong/article/details/7950084

线性回归，顾名思义，属于回归问题。既然是回归问题，那必然属于监督学习。

什么是回归问题呢？

回归用于预测输入变量（x）和输出变量(y)之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。回归模型正是表示从输入变量到输出变量之间映射的函数，回归问题的学习等价于函数拟合：选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据。

​		线性回归的定义是：目标值预期是输入变量的线性组合。线性模型形式简单、易于建模，但却蕴含着机器学习中一些重要的基本思想。线性回归，是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。
简单来说，就是选择一条线性函数来很好的拟合已知数据并预测未知数据。

​		*线性回归*（linear regression）可以追溯到19世纪初， 它在回归的各种标准工具中最简单而且最流行。 线性回归基于几个简单的假设： 首先，假设自变量x和因变量y之间的关系是线性的， 即y可以表示为x中元素的加权和，这里通常允许包含观测值的一些噪声； 其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。

​		回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。

​		为了解释*线性回归*，我们举一个实际的例子： 我们希望根据房屋的面积（平方英尺）和房龄（年）来估算房屋价格（美元）。 为了开发一个能预测房价的模型，我们需要收集一个真实的数据集。 这个数据集包括了房屋的销售价格、面积和房龄。 在机器学习的术语中，该数据集称为*训练数据集*（training data set） 或*训练集*（training set）。 每行数据（比如一次房屋交易相对应的数据）称为*样本*（sample）， 也可以称为*数据点*（data point）或*数据样本*（data instance）。 我们把试图预测的目标（比如预测房屋价格）称为*标签*（label）或*目标*（target）。 预测所依据的自变量（面积和房龄）称为*特征*（feature）或*协变量*（covariate）。

​		通常，我们使用n来表示数据集中的样本数。 对索引为i的样本，其输入表示为:
$$
x(i)=[x1(i),x2(i)]⊤
$$
 其对应的标签是y(i)。



# 线性模型

​		线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和，如下面的式子：

​		
$$
\mathrm{price} = w_{\mathrm{area}} \cdot \mathrm{area} + w_{\mathrm{age}} \cdot \mathrm{age} + b.
$$

$$

$$
