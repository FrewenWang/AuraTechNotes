---
title: Linux系统上常用软件集锦
date: 2020-07-20 00:00:00
updated: 2022-01-05 00:00:00
tags: [Linux,四大组件,Activity]
type: [Linux,四大组件,Activity]
comments: Activity的生命周期完全解析
description: Activity的生命周期完全解析
keywords: Activity的生命周期完全解析
top_img:
mathjax:
katex:
aside:
aplayer:
highlight_shrink:


---

[TOC]

# 概述

## QNN框架量化文档

在量化或非量化模型之间进行选择：

- CPU - 选择非量化模型。量化模型目前与 CPU 后端不兼容。
- DSP - 选择一个量化模型。在 DSP 后端运行时需要量化模型。
- GPU - 选择非量化模型。量化模型目前与 GPU 后端不兼容。
- HTP - 选择一个量化模型。在 HTP 后端运行时需要量化模型。
- HTA - 选择一个量化模型。在 HTA 后端运行时需要量化模型。

QNN 支持多种量化模式。此处描述了量化的基础知识，无论模式如何。

- 量化使用提供的位宽将浮点数据转换为 Tensorflow 风格的定点格式。

- 满足以下要求：

  - 涵盖了所有输入值。

  - 强制执行最小范围 0.01。
  - 浮点零是完全可表示的。

- 量化算法输入：
  - 要量化的浮点值集。



- 量化算法输出：
  - 一组 8 位定点值。
  - 编码参数：
    - encoding-min - 可表示的最小浮点值（通过定点值 0）
    - encoding-max - 可表示的最大浮点值（定点值 255）
    - scale - 给定范围的步长 (max - min) / (2^bw-1)
    - offset - 精确表示 0 的整数值。 round(-min/scale)

- 算法

  1. 计算输入数据的真实范围（最小值、最大值）。
  2. 计算 encoding-min 和 encoding-max。
  3. 量化输入浮点值。
  4. 输出：

  > - fixed point values
  > - encoding-min and encoding-max parameters
  > - scale and offset parameters





### 量化模式

QNN 支持四种量化模式：tf、对称、增强和调整。主要区别在于他们如何选择要使用的量化范围。

#### tf

上面已经描述了默认模式，它使用被量化数据的真实最小值/最大值，然后调整范围以确保最小范围并确保 0.0 可精确量化。

####  增强

增强量化模式（通过将“增强”传递给[转换器](tools.html)`--param_quantizer`中的一个或`--act_quantizer`选项来调用）使用一种算法来尝试确定一组更好的量化参数以提高准确性。该算法可能会选择与默认量化器不同的最小/最大值，并且在某些情况下，它可能会设置范围以使某些原始权重和/或激活不能落入该范围。然而，这个范围确实比简单地使用真正的最小值/最大值产生更好的准确度。通过在选项后附加“权重”或“激活”，可以为权重和激活独立启用增强的量化器。



### 如何量化

要启用量化，只需将选项 –input_list 与包含原始数据输入的文本文件一起传递给网络。请注意，此文件中指定的输入应与转换生成的 .cpp 文件中的输入完全匹配。在大多数情况下，这些输入可以直接从源框架模型中获得。但是，在极少数情况下，例如当输入被转换器修剪时，这些输入可能会有所不同。该文件的格式对网络的每组输入使用一行：















## QNN模型接入问题



1. 排查量化损失导致问题，我们可以查找是weights还是activation导致的量化损失



![image-20220704112751364](images/image-20220704112751364.png)

### weights量化损失：



将模型抓化成dlc模型，再将模型运行在CPU上。





### activation量化损失：



sqnr计算量化功能，和余弦相似度差不多



#### sqnr公式

sqnr的值是比较合理的，大部分根据模型来定义。目标检测的的sqnr的



#### 余弦相似度

超级夜景需要保证小数点后面5个9. 其他的模型保证小数点后面3个9即可。

根据模型计算，至少需要保证小数点后2个9即可。



如果中间某个网络层出现比较低的余弦相似度，但是最后的余弦相似度输出比较高。这个也不是不太好的。比如如果最后一层输出的是二分类的问题。但是恰好的输出的值一致。



#### BN的公式







### 设计成batchNormallization

使用batchNarmal的



1. 如果训练的代价不是很大，可以尝试把所有的batchNormalization的去掉。
2. 训练的时候，搜索算法的时候需要注意卷积的通道数据最好是32的整数倍否则效率会很低。例如10通道和32通道
3. 之前说卷积和BN拆开来计算，如果拆开之后，先计算卷积和在计算BN的
4. 





训练的时候主要通道数，

![image-20220704142109843](images/image-20220704142109843.png)







## QNN量化



<img src="images/image-20220704153544933.png" alt="image-20220704153544933" style="zoom:50%;" />













肯定是追求泛化效果，是对的。

500张之后，应该是对一批的数据的余弦相似度的应该都是比较好的









<img src="images/image-20220704160255231.png" alt="image-20220704160255231" style="zoom:50%;" />















## 解决量化精度问题

### 采集实车数据

工程现有的配置是根据算法一开始提供的500张图片，参与模型的量化输入的；如果把集度提供的这张图片放进去重新量化，就没有问题；问题本质就是QA同学一开始说的人脸miss，一个性质。就是通用数据进行量化的时候，其实不能完全兼容实车数据的图片范围，

初步判断是模型量化后产生的精度损失，接下来需要针对集度实车camera采集各个场景下的少量数据集进行补充，通过实车量产状态下采集的图片数据、参与模型量化过程中激活层的配置，进一步提高量化后的精度；









