---
title: 深度神经网络模型量化方法基础
date: 2022-01-05 00:00:00
updated: 2022-01-05 00:00:00
tags: [神经网络,网络量化,量化方法]
type: [神经网络,网络量化,量化方法]
comments: 性能优化框架介绍
description: 页面描述
keywords: 关键字
top_img:
mathjax:
katex:
aside:
aplayer:
highlight_shrink:

---

[TOC]

文章参考：https://zhuanlan.zhihu.com/p/149659607

# 概述

上面讲解了基本的量化公式和量化的方法，下面来详细展开感知量化训练（Aware Quantization）模型中插入伪量化节点fake quant来模拟量化引入的误差。端测推理的时候折叠fake quant节点中的属性到tensor中，在端测推理的过程中直接使用tensor中带有的量化属性参数。



伪量化节点（Fake Quant）的意义在于：

1）找到输入数据的分布，即找到min和max值；

2）模拟量化到低比特操作的时候的精度损失，把该损失作用到网络模型中，传递给损失函数，让优化器去在训练过程中对该损失值进行优化。



# 量化基本原理

低比特量化模型运行时，需要确定$scale$与$offset$两个量化参数：
$$
float=scale*(uint8 + offset)
$$
其中，是float32浮点数，uint8为unsigned int定点数，offset是int32定点数。其表示的数据范围为：



 

# 感知训练量化



# 量化方法

## 矩阵运算量化

由于卷积网络中的卷积层和全连接层本质上都是一堆矩阵乘法，因此我们先看如何将浮点运算上的矩阵转换为定点运算。

讲解了基本的量化公式和量化的方法，下面来详细展开感知量化训练（Aware Quantization）模型中插入伪量化节点fake quant来模拟量化引入的误差。端测推理的时候折叠fake quant节点中的属性到tensor中，在端测推理的过程中直接使用tensor中带有的量化属性参数。



## 卷积网络的量化

有了上面矩阵乘法的量化，我们就可以进一步尝试对卷积网络的量化。

假设一个这样的网络：







## BN折叠

初步实施方案中构图比较复杂的主要集中在如何拆分BN层，本节将会对拆分的原理进行细化，落实确定到每一个算子上面，包括每个算子的具体计算公式，控制原理。







