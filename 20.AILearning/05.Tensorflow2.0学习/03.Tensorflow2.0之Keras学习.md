---
title: Tensorflow的基础介绍
date: 2020-07-20 00:00:00
updated: 2022-01-05 00:00:00
tags: [Tensorflow,人工智能,深度学习]
type: [Tensorflow,人工智能,深度学习]
comments: 
description:
keywords: 
top_img:
mathjax:
katex:
aside:
aplayer:
highlight_shrink:
---

[TOC]

# 概述

Keras已经成为Tensorflow的官方的API

基于python的高级神经网络的API





### Keras中的数据集

Boston_housing   波士顿房价数据集

CIFAR10			10种类别的图片集

CIFAR100		   100种类别的图片集

MNIST				 手写数组图片集

Fashion-MNIST	10种时尚类别的图片集

IMDB					 电影点评数据集

reuters					路透社新闻数据集



### 理论部分

Tensorflow-keras简介

Tensorflow-keras的同一套API



Tf-keras全面支持eager mode

只是使用keras.Sequential和keras'



 Tf-keras支持基于tf.data的模型训练

Tf.keras支持TPU训练

Tf.keras支持tf.distribution中的分布式策略

其他特性

​		





分类问题、回归函数、损失函数

 神经函数、激活函数、拟归一化、Dropout

Wide&deep模型

超参数搜索

### 实战部分

Keras搭建分类模型

Keras回调函数

Keras搭建回归模型

Keras搭建深度神经网络

Keras实现wide&deep模型

Keras与scikit-learn实现超参数搜索

### Keras是什么



### Tensorflow-keras是什么





### TF-Keras和Keras如何选择

如果想使用tf.keras的任何一个特性，那么选择tf.keras

如果后端互换性很重要，那么选择keras

如果都不重要，那么随便



### 分类问题和回归问题学习

分类问题预测的是类别，模型的输出是概率的分布

三分类问题的输出的例子：[0.2,0.7,0.1]

回归问题预测的是值，模型输出的是一个实数值



### 目标函数

参数逐步调整

目标函数可以精确的帮助我们衡量模型的好坏

对于分类问题，需要衡量目标类别与当前预测的差距

 

#### 分类问题

<img src="https://gitee.com/frewen1225/ImageUploader/raw/master/img/20210710154744.png" alt="image-20210710154744282" style="zoom:50%;" />



举例

平方差损失举例：

预测值：[0.2,0.7,0.1]

真实值：[0,0,1]

损失函数：[(0.2-0)^2 + (0.7-0)^2+ (0.1-1)^2]*0.5 = 0.65



```python
# 这个库在python中是用来进行画图
import matplotlib as mpl
import matplotlib.pyplot as plt
%matplotlib inline

import numpy as np
import sklearn 

#  pandas是在python中进行处理数据的库
import pandas as pd
import os,sys,time
 
import tensorflow as tf
# keras有两类keras。我们可以自己进行选择，使用ts-keras还是keras。
# import keras。在这里我们使用tensorflow-keras
from tensorflow import keras

# 我们先进行打印一下我们所有的依赖库的版本号
print(tf.__version__)
print(sys.version_info)

for module in mpl,np,pd,sklearn,tf,keras:
    print(module.__name__,module.__version__)

# 我们使用keras来搭建一个分类模型.我们学习使用分类模型的，
# 我们可以kera内置的数据集。导入数据集fashion_mnist
fashion_mnist = keras.datasets.fashion_mnist
# 我们从这个kera内置的数据集fashion_mnist拆分出训练集和测试集
# python中通过变量
(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()
# 一般情况下，我们需要将训练集拆分成训练集和验证集
# 我们使用前 5000张作为验证集，然后使用其余的图片作为选连接
x_valid, x_train = x_train_all[:5000], x_train_all[5000:]
y_valid, y_train = y_train_all[:5000], y_train_all[5000:]
 
# 我们依次打印训练集、验证集、测试集的数据
print("====================训练集======================")
print(x_train.shape,y_train.shape)
print("====================验证集======================")
print(x_valid.shape,y_valid.shape)
print("====================测试集======================")
print(x_test.shape,y_test.shape)

def show_single_image(img_array):
    #  matplotlib.pyplot   
    plt.imshow(img_array,cmap="binary")
    plt.show()

    
show_single_image(x_train[0])

# 这个我们是从Tensorflow官网上面找到的。这个fashion_mnist数据集中各个图像对应的类别
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

def show_all_images(n_rows,n_cols,x_data,y_data,class_names):
    assert len(x_data) == len(y_data)
    # 这里是需要断言，我们打印的数据数量不能大约原始数据集的数量
    assert n_rows * n_cols < len(x_data)
    # 配置我们需要显示的图片的size 我们是将
    plt.figure(figsize = (n_rows*5,n_cols *1.2))
    for row in range(n_rows):
        for col in range(n_cols):
            # 行列的数据转化为我们数据集中的index索引值
            index = n_cols * row + col
            plt.subplot(n_rows,n_cols,index+1)
            # 缩放图片的差值器，使用最近的像素点
            plt.imshow(x_data[index],cmap="binary",interpolation = 'nearest')
            plt.axis('off')
            # y_data数据集合中存储的是x_data里面图像的对应的名称
            plt.title(class_names[y_data[index]])
    plt.show()
# 我们按照三行五列的打印形式打印出这个数据集合    
show_all_images(3,6,x_train,y_train,class_names)   

# 下面，我们就可以进行构建我们的分类模型
# 我们使用tf.keras.models.Sequential(). 我们可以看到一下他的API

# https://tensorflow.google.cn/tutorials/keras/classification
# Sequential 将层的线性堆栈分组到 tf.keras.Model 中。继承自：模型、层、模块

"""
# 模型添加层的第一种方法
model = keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=[28, 28]))
model.add(keras.layers.Dense(300, activation="relu"))
model.add(keras.layers.Dense(100, activation="relu"))
model.add(keras.layers.Dense(10, activation="softmax"))
"""

# 模型添加层的第二种方法
model = keras.models.Sequential([
    # 往模型对象里面添加层次。这一层是往模型里面添加输入28*28的图像  Flatten是展平为一维向量。
    keras.layers.Flatten(input_shape=[28, 28]),
    # 这层是添加全连接层
    # activation是激活函数。激活函数
    # 全连接层就是神经网络中最普通的神经网络，下一层和上一层进行全连接
    keras.layers.Dense(300, activation='relu'),
    # 和上面一层进行全连接。再添加一层全连接层
    keras.layers.Dense(100, activation='relu'),
    # 这一层我们让他输出为长度为10的向量。因为我们的衣服种类就是十种。激活函数是softmax
    keras.layers.Dense(10,activation='softmax')
])

# 激活函数：
#  relu: y=max(0,x) 输出x和0中最大的数字
#  softmax 这个函数做的事情就是将向量编程概率分布。
#  具体的做法就是：x=[x1,x2,x3]
#  y=[e^x1/sum,e^x2/sum,e^x3/sum] sum = e^x1 + e^x2 + e^x3

#  loss 损失函数 sparse_categorical_crossentropy 就是交叉熵损失函数
# 使用sparse的原因： y是一个index的值  y->index y->one_hot ->[]
# optimizer="sgd" 模型的求解函数
# metrics = ["accuracy"] 把损失函数还有优化方法
model.compile(loss="sparse_categorical_crossentropy",
              optimizer ="sgd",
              metrics = ["accuracy"])
              
              
 # 查看这个模型有多少
# 查看这个模型有多少层
model.layers

model.summary()
# model.summary()是一个含很有用的函数。他可以打印出这个模型的概况。
# 他可以告诉我们模型中一共有多少个参数，有哪些参数是可以训练的。


# 上面的逻辑我们来梳理一下：
# 我们看一下全连接层的参数的个数是怎么计算出来的？？
# 那么全连接层是什么？ 我们以第一层和第二层来讲解一下
# 在第一层中他是一个样本数784的一个矩阵  [None,784] 经过全连接后我们需要把他变成一个样本数 300的一个矩阵：[None,784] -> [None,300]
# 那么需要怎么来做呢？我们需要让他乘以一个矩阵，再加一个偏置函数B  矩阵w就是大小就是[784,300].b就是一个长度为300的向量
# [None,784] * W + b-> [None,300]


# 我们可以开始进行训练模型了
# 下面的方法就是我们把训练集放到这个模型里面。并且epochs = 10我们进行训练10次
# 同时我们加入了验证数据集。validation_data=(x_valid,y_valid)这样每隔一段时间他就是进行验证。
# 这个训练方法是可以返回一个值的。这个返回值就是中间运行的结果。我们称之为history
history=model.fit(x_train,y_train,
                  epochs = 10,
                  validation_data=(x_valid,y_valid))

# TODO 模型训练并没有成功
# 后面我们做了数据归一化之后。就可以训练成功了。为什么数据归一化之后，模型可以训练成功。数据归一化的目的是什么？？


# History其实就是keras的一个callback的值
type(history)

history.history

# 我们可以把上面的histoty按照图标的形式打印出来
def plot_learning_curves(history):
    # plot_learning_curves是pandas里面一个很重要的数据结构
    pd.DataFrame(history.history).plot(figsize=(8,5))
    # 显示成网格的形式
    plt.grid(True)
    # 我们设计数据的范围
    plt.gca().set_ylim(0,1)
    plt.show()

plot_learning_curves(history)   
```





#### 回归问题

预测值与真实值之间的差距

平方差损失

绝对值损失





## 实战

使用keras搭建分类模型。然后使用keras的回调函数去执行其他的操作

使用Kera搭建回归模型。

```python

```







## Keras的API





```
(tensorflow2-py38) ➜  keras git:(main) ✗ tensorboard --logdir=callbacks                                              

NOTE: Using experimental fast data loading logic. To disable, pass
    "--load_fast=false" and report issues on GitHub. More details:
    https://github.com/tensorflow/tensorboard/issues/4784

Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
TensorBoard 2.5.0 at http://localhost:6006/ (Press CTRL+C to quit)

```





## 问题

https://stackoverflow.com/questions/71104727/keras-assertionerror-duplicate-registrations-for-type-experimentaloptimizer

```shell
# 卸载之前的版本
uninstall:
keras
keras-nightly
keras-preprocessing
tensorboard
tensorflow
tb-nightly
tf-nightly
# 重新安装
pip3 install tensorflow
```























